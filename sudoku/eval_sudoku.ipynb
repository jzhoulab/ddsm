{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Evaluaing Sudoku Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import functools\n",
    "import random, copy\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from ddsm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load presampled noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_one, v_zero, v_one_loggrad, v_zero_loggrad, timepoints = torch.load('steps400.cat9.time1.0.samples100000.pth')\n",
    "torch.set_default_dtype(torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aae31993670>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(v_one[:,-1,0].detach().cpu(), v_one_loggrad[:,-1,0].detach().cpu(),'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define several functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_puzzle_solution():\n",
    "    \"\"\"\n",
    "    Randomly arrange numbers in a grid while making all rows, columns and\n",
    "    squares (sub-grids) contain the numbers 1 through 9.\n",
    "    For example, \"sample\" (above) could be the output of this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop until we're able to fill all 81 cells with numbers, while\n",
    "    # satisfying the constraints above.\n",
    "    while True:\n",
    "        try:\n",
    "            puzzle  = [[0]*9 for i in range(9)] # start with blank puzzle\n",
    "            rows    = [set(range(1,10)) for i in range(9)] # set of available\n",
    "            columns = [set(range(1,10)) for i in range(9)] #   numbers for each\n",
    "            squares = [set(range(1,10)) for i in range(9)] #   row, column and square\n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    # pick a number for cell (i,j) from the set of remaining available numbers\n",
    "                    choices = rows[i].intersection(columns[j]).intersection(squares[(i//3)*3 + j//3])\n",
    "                    choice  = random.choice(list(choices))\n",
    "        \n",
    "                    puzzle[i][j] = choice\n",
    "        \n",
    "                    rows[i].discard(choice)\n",
    "                    columns[j].discard(choice)\n",
    "                    squares[(i//3)*3 + j//3].discard(choice)\n",
    "\n",
    "            # success! every cell is filled.\n",
    "            return puzzle\n",
    "            \n",
    "        except IndexError:\n",
    "            # if there is an IndexError, we have worked ourselves in a corner (we just start over)\n",
    "            pass\n",
    "\n",
    "def pluck(puzzle, n=0):\n",
    "\n",
    "    \"\"\"\n",
    "    Randomly pluck out cells (numbers) from the solved puzzle grid, ensuring that any\n",
    "    plucked number can still be deduced from the remaining cells.\n",
    "    For deduction to be possible, each other cell in the plucked number's row, column,\n",
    "    or square must not be able to contain that number.\n",
    "\n",
    "    Answers the question: can the cell (i,j) in the puzzle \"puz\" contain the number\n",
    "    in cell \"c\"? \"\"\"\n",
    "    def canBeA(puz, i, j, c):\n",
    "        v = puz[c//9][c%9]\n",
    "        if puz[i][j] == v: return True\n",
    "        if puz[i][j] in range(1,10): return False\n",
    "            \n",
    "        for m in range(9): # test row, col, square\n",
    "            # if not the cell itself, and the mth cell of the group contains the value v, then \"no\"\n",
    "            if not (m==c//9 and j==c%9) and puz[m][j] == v: return False\n",
    "            if not (i==c//9 and m==c%9) and puz[i][m] == v: return False\n",
    "            if not ((i//3)*3 + m//3==c//9 and (j//3)*3 + m%3==c%9) and puz[(i//3)*3 + m//3][(j//3)*3 + m%3] == v:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    starts with a set of all 81 cells, and tries to remove one (randomly) at a time\n",
    "    but not before checking that the cell can still be deduced from the remaining cells. \"\"\"\n",
    "    cells     = set(range(81))\n",
    "    cellsleft = cells.copy()\n",
    "    while len(cells) > n and len(cellsleft):\n",
    "        cell = random.choice(list(cellsleft)) # choose a cell from ones we haven't tried\n",
    "        cellsleft.discard(cell) # record that we are trying this cell\n",
    "\n",
    "        # row, col and square record whether another cell in those groups could also take\n",
    "        # on the value we are trying to pluck. (If another cell can, then we can't use the\n",
    "        # group to deduce this value.) If all three groups are True, then we cannot pluck\n",
    "        # this cell and must try another one.\n",
    "        row = col = square = False\n",
    "\n",
    "        for i in range(9):\n",
    "            if i != cell//9:\n",
    "                if canBeA(puzzle, i, cell%9, cell): row = True\n",
    "            if i != cell%9:\n",
    "                if canBeA(puzzle, cell//9, i, cell): col = True\n",
    "            if not (((cell//9)//3)*3 + i//3 == cell//9 and ((cell//9)%3)*3 + i%3 == cell%9):\n",
    "                if canBeA(puzzle, ((cell//9)//3)*3 + i//3, ((cell//9)%3)*3 + i%3, cell): square = True\n",
    "\n",
    "        if row and col and square:\n",
    "            continue # could not pluck this cell, try again.\n",
    "        else:\n",
    "            # this is a pluckable cell!\n",
    "            puzzle[cell//9][cell%9] = 0 # 0 denotes a blank cell\n",
    "            cells.discard(cell) # remove from the set of visible cells (pluck it)\n",
    "            # we don't need to reset \"cellsleft\" because if a cell was not pluckable\n",
    "            # earlier, then it will still not be pluckable now (with less information\n",
    "            # on the board).\n",
    "\n",
    "    # This is the puzzle we found, in all its glory.\n",
    "    return (puzzle, len(cells))\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "That's it.\n",
    "If we want to make a puzzle we can do this:\n",
    "    pluck(construct_puzzle_solution())\n",
    "    \n",
    "The following functions are convenience functions for doing just that...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This uses the above functions to create a new puzzle. It attempts to\n",
    "create one with 28 (by default) given cells, but if it can't, it returns\n",
    "one with as few givens as it is able to find.\n",
    "This function actually tries making 100 puzzles (by default) and returns\n",
    "all of them. The \"best\" function that follows this one selects the best\n",
    "one of those.\n",
    "\"\"\"\n",
    "def run(n = 28, iter=100):\n",
    "    all_results = {}\n",
    "#     print \"Constructing a sudoku puzzle.\"\n",
    "#     print \"* creating the solution...\"\n",
    "    a_puzzle_solution = construct_puzzle_solution()\n",
    "    \n",
    "#     print \"* constructing a puzzle...\"\n",
    "    for i in range(iter):\n",
    "        puzzle = copy.deepcopy(a_puzzle_solution)\n",
    "        (result, number_of_cells) = pluck(puzzle, n)\n",
    "        all_results.setdefault(number_of_cells, []).append(result)\n",
    "        if number_of_cells <= n: break\n",
    " \n",
    "    return all_results, a_puzzle_solution\n",
    "\n",
    "def best(set_of_puzzles):\n",
    "    # Could run some evaluation function here. For now just pick\n",
    "    # the one with the fewest \"givens\".\n",
    "    return set_of_puzzles[min(set_of_puzzles.keys())][0]\n",
    "\n",
    "def display(puzzle):\n",
    "    for row in puzzle:\n",
    "        print(' '.join([str(n or '_') for n in row]))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def gen_sudoku(num):\n",
    "    '''\n",
    "    Generates `num` games of Sudoku.\n",
    "    '''\n",
    "    solutions = np.zeros((num, 9, 9), np.int32)\n",
    "    for i in range(num):\n",
    "        solutions[i] = construct_puzzle_solution()\n",
    "\n",
    "    return solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_puzzle_solution_successrate(total_success):\n",
    "    # Loop until we're able to fill all 81 cells with numbers, while\n",
    "    # satisfying the constraints above.\n",
    "    nfailure=0\n",
    "    nsuccess=0\n",
    "    while nsuccess<total_success:\n",
    "        try:\n",
    "            puzzle  = [[0]*9 for i in range(9)] # start with blank puzzle\n",
    "            rows    = [set(range(1,10)) for i in range(9)] # set of available\n",
    "            columns = [set(range(1,10)) for i in range(9)] #   numbers for each\n",
    "            squares = [set(range(1,10)) for i in range(9)] #   row, column and square\n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    # pick a number for cell (i,j) from the set of remaining available numbers\n",
    "                    choices = rows[i].intersection(columns[j]).intersection(squares[(i//3)*3 + j//3])\n",
    "                    choice  = random.choice(list(choices))\n",
    "        \n",
    "                    puzzle[i][j] = choice\n",
    "        \n",
    "                    rows[i].discard(choice)\n",
    "                    columns[j].discard(choice)\n",
    "                    squares[(i//3)*3 + j//3].discard(choice)\n",
    "\n",
    "            # success! every cell is filled.\n",
    "            nsuccess += 1\n",
    "            \n",
    "        except IndexError:\n",
    "            print('fail')\n",
    "            nfailure += 1\n",
    "            pass\n",
    "    return nsuccess / nfailure\n",
    "#construct_puzzle_solution(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check sudoku correctness\n",
    "def sudoku_acc(sample, return_array=False):\n",
    "    sample = sample.detach().cpu().numpy()\n",
    "    correct = 0\n",
    "    total = sample.shape[0]\n",
    "    ans = sample.argmax(-1)+1\n",
    "    numbers_1_N = np.arange(1, 9 + 1)\n",
    "    corrects = []\n",
    "    for board in ans:\n",
    "        if (np.all(np.sort(board, axis=1) == numbers_1_N) and\n",
    "            np.all(np.sort(board.T, axis=1) == numbers_1_N)):\n",
    "            # Check blocks\n",
    "            \n",
    "            blocks = board.reshape(3, 3, 3, 3).transpose(0, 2, 1, 3).reshape(9, 9)\n",
    "            if np.all(np.sort(board.T, axis=1) == numbers_1_N):\n",
    "                correct += 1\n",
    "                corrects.append(True)\n",
    "            else:\n",
    "                corrects.append(False)\n",
    "        else:\n",
    "            corrects.append(False)\n",
    "\n",
    "    if return_array:\n",
    "        return corrects\n",
    "    else:\n",
    "        print('correct {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colind = np.array([[0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8]])\n",
    "\n",
    "rowind = np.array([[0,0,0,0,0,0,0,0,0],\n",
    "          [1,1,1,1,1,1,1,1,1],\n",
    "          [2,2,2,2,2,2,2,2,2],\n",
    "          [3,3,3,3,3,3,3,3,3],\n",
    "          [4,4,4,4,4,4,4,4,4],\n",
    "          [5,5,5,5,5,5,5,5,5],\n",
    "          [6,6,6,6,6,6,6,6,6],\n",
    "          [7,7,7,7,7,7,7,7,7],\n",
    "          [8,8,8,8,8,8,8,8,8]])\n",
    "\n",
    "\n",
    "blockind = np.array([[0,0,0,1,1,1,2,2,2],\n",
    "          [0,0,0,1,1,1,2,2,2],\n",
    "          [0,0,0,1,1,1,2,2,2],\n",
    "          [3,3,3,4,4,4,5,5,5],\n",
    "          [3,3,3,4,4,4,5,5,5],\n",
    "          [3,3,3,4,4,4,5,5,5],\n",
    "          [6,6,6,7,7,7,8,8,8],\n",
    "          [6,6,6,7,7,7,8,8,8],\n",
    "          [6,6,6,7,7,7,8,8,8]])\n",
    "\n",
    "colenc = np.zeros((81,9))\n",
    "rowenc = np.zeros((81,9))\n",
    "blockenc = np.zeros((81,9))\n",
    "colenc[np.arange(81),colind.flatten()] = 1\n",
    "rowenc[np.arange(81),rowind.flatten()] = 1\n",
    "blockenc[np.arange(81),blockind.flatten()] = 1\n",
    "allenc = np.concatenate([colenc, rowenc, blockenc], axis=1)\n",
    "allenc_relative = torch.FloatTensor(allenc[:,None,:]==allenc[None,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sudoku dataloader that generate sudoku in real-time\n",
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return int(batchSize*1000)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sudoku = gen_sudoku(1)\n",
    "        dataset = np.eye(9)[sudoku.reshape(sudoku.shape[0],-1)-1]\n",
    "        return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate time dependent weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importance sampling weights \n",
    "#this part may change, no need to spend too much time on understanding it\n",
    "device = 'cuda'\n",
    "batchSize = 256 \n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(worker_id)\n",
    "\n",
    "sb = UnitStickBreakingTransform()\n",
    "ds = SudokuDataset()\n",
    "train_dataloader = DataLoader(ds, batchSize, shuffle=True, num_workers=16, worker_init_fn=worker_init_fn)\n",
    "\n",
    "time_dependent_cums = torch.zeros(timepoints.shape[0]).to(device)\n",
    "time_dependent_counts = torch.zeros(timepoints.shape[0]).to(device)\n",
    "\n",
    "avg_loss = 0.\n",
    "num_items = 0\n",
    "for i, x in enumerate(train_dataloader):\n",
    "    x = x.reshape(-1,9,9,9)\n",
    "    random_t = torch.randint(0, timepoints.shape[0], (x.shape[0],))\n",
    "    order = np.random.permutation(np.arange(9))\n",
    "    #perturbed_x, perturbed_x_grad = diffusion_factory(x[...,order], random_t,  v_one, v_zero,v_one_loggrad, v_zero_loggrad, alpha, beta)\n",
    "    perturbed_x, perturbed_x_grad = diffusion_fast_flatdirichlet(x[...,order], random_t, v_one, v_one_loggrad)\n",
    "    perturbed_x = perturbed_x[..., np.argsort(order)]\n",
    "    perturbed_x_grad = perturbed_x_grad[..., np.argsort(order)]\n",
    "    perturbed_x = perturbed_x.to(device)    \n",
    "    perturbed_x_grad = perturbed_x_grad.to(device)\n",
    "    random_t = random_t.to(device)\n",
    "    perturbed_v = sb._inverse(perturbed_x)\n",
    "\n",
    "    \n",
    "    order = np.random.permutation(np.arange(9))\n",
    "    perturbed_v = sb._inverse(perturbed_x[..., order], prevent_nan=True).detach()\n",
    "\n",
    "    time_dependent_counts[random_t] += 1\n",
    "    #time_dependent_cums[random_t] +=  ( ((perturbed_x)*(1-perturbed_x))**2 * (perturbed_x_grad)**2).mean(dim=(1,2,3)).detach()\n",
    "    time_dependent_cums[random_t] +=  (perturbed_v*(1-perturbed_v) * (gx_to_gv(perturbed_x_grad[...,order],perturbed_x[...,order]))**2).mean(dim=(1,2,3)).detach()\n",
    "    time_dependent_weights =  time_dependent_cums / time_dependent_counts\n",
    "    time_dependent_weights = time_dependent_weights / time_dependent_weights.mean()\n",
    "    \n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aabce7af6d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_dependent_weights.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified from minGPT \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n",
    "    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
    "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
    "    explicit implementation here to show that there is nothing too scary here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, bias=None):\n",
    "        super().__init__()\n",
    "        assert n_embd % n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(n_embd, 3 * n_embd)\n",
    "        self.c_proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.n_embd = n_embd\n",
    "        self.register_buffer(\"bias\",bias)\n",
    "        \n",
    "        self.bias_proj = nn.Linear(bias.shape[-1], n_head) #T, T, nh\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att + self.bias_proj(self.bias).permute((2,0,1))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        #att = self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" an unassuming Transformer block \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, bias=None):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(n_embd)\n",
    "        self.attn = SelfAttention(n_embd, n_head, bias=bias)\n",
    "        self.ln_2 = nn.LayerNorm(n_embd)\n",
    "        self.mlp = nn.ModuleDict(dict(\n",
    "            c_fc    = nn.Linear(n_embd, 4 * n_embd),\n",
    "            c_proj  = nn.Linear(4 * n_embd, n_embd),\n",
    "            act     = NewGELU(),\n",
    "        ))\n",
    "        m = self.mlp\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp.c_proj(self.mlp.act(self.mlp.c_fc(self.ln_2(x))))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Gaussian random features for encoding time steps.\n",
    "    \"\"\"  \n",
    "    \n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A fully connected layer that reshapes outputs to feature maps.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)[...]\n",
    "\n",
    "    \n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, allenc_rel, embed_dim=256, ):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    \n",
    "    self.linear = Dense(9,128)\n",
    "    self.blocks = nn.ModuleList(Block(128, 8, bias=allenc_rel) for _ in range(20))\n",
    "    self.denses = nn.ModuleList(Dense(embed_dim, 128) for _ in range(20))\n",
    "    self.act = NewGELU()\n",
    "    self.softplus = nn.Softplus()\n",
    "    self.output = Dense(128,9)\n",
    "    self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "  \n",
    "  def forward(self, x, t): \n",
    "    # Obtain the Gaussian random feature embedding for t   \n",
    "    embed = self.act(self.embed(t))\n",
    "    \n",
    "    # Encoding path\n",
    "    h =   self.linear(x.view(-1,81,9))\n",
    "    for le, ld in zip(self.blocks, self.denses):\n",
    "        h = le(h + ld(embed)[:,None,:])\n",
    "\n",
    "    h = self.output(h)\n",
    "\n",
    "    #h = h.reshape(x.size()) * torch.exp(-t[:,None,None,None]* self.softplus(self.scale)) /  ((x+1e-6)*(1-x+1e-6))\n",
    "    h = h.reshape(x.size()) #* torch.exp(-t[:,None,None,None]* self.softplus(self.scale)) * (1/(x+1e-3)+1/(1-x+1e-3))\n",
    "    h = h - h.mean(axis=-1, keepdims=True)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ScoreNet(\n",
       "    (embed): Sequential(\n",
       "      (0): GaussianFourierProjection()\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear): Dense(\n",
       "      (dense): Linear(in_features=9, out_features=128, bias=True)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (denses): ModuleList(\n",
       "      (0): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (1): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (2): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (3): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (4): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (5): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (6): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (7): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (8): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (9): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (10): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (11): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (12): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (13): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (14): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (15): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (16): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (17): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (18): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (19): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (act): NewGELU()\n",
       "    (softplus): Softplus(beta=1, threshold=20)\n",
       "    (output): Dense(\n",
       "      (dense): Linear(in_features=128, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = nn.DataParallel(ScoreNet(allenc_relative))\n",
    "score_model.module.load_state_dict(torch.load('../best_model_weights/sudoku/sudoku.transformer.pth'))\n",
    "score_model = score_model.to('cuda')\n",
    "score_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:32<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n"
     ]
    }
   ],
   "source": [
    "device='cuda'\n",
    "score_model.eval()\n",
    "acc = []\n",
    "samples = Euler_Maruyama_sampler(score_model,\n",
    "                  (9,9,9), \n",
    "                  batch_size=256,\n",
    "                  max_time=1, \n",
    "                  min_time=0.01,\n",
    "                  time_dilation=8,\n",
    "                  num_steps=100,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=False,\n",
    "                  device=device)\n",
    "acc.append(sudoku_acc(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "Generate results for table 2 - Sudoku Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:04<00:00, 24.67it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.13it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.12it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.16it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.16it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.23it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.25it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.12it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.25it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936328125 0.004160558674132931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:07<00:00, 25.30it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.30it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.27it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.14it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.11it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.18it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.28it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.25it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.10it/s]\n",
      "100%|| 200/200 [00:08<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99375 0.0013278696649981208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:16<00:00, 24.99it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.20it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.22it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.09it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.25it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.16it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.20it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.06it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.04it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984375 0.0006378879538497859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:31<00:00, 25.14it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.18it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.13it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.16it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.06it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.24it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.22it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.16it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.24it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999609375 0.0003906250000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for time_dilation in [1, 2, 4, 8]:\n",
    "    acc = []\n",
    "    for i in range(10):\n",
    "        score_model.eval()\n",
    "        samples = Euler_Maruyama_sampler(score_model,\n",
    "                          (9,9,9),\n",
    "                          batch_size=256,\n",
    "                          max_time=1,\n",
    "                          min_time=0.01,\n",
    "                          time_dilation=time_dilation,\n",
    "                          num_steps=100,\n",
    "                          random_order=False,\n",
    "                          speed_balanced=True,\n",
    "                          speed_factor=9./2., \n",
    "                          device=device)\n",
    "        acc.append(np.mean(sudoku_acc(samples, return_array=True)))\n",
    "    print(np.mean(acc), np.std(acc)/np.sqrt(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving SatNet Puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#satnet puzzles\n",
    "sat_puzzles = torch.load('../data/satnet_sudoku/features.pt').argmax(-1) + 1\n",
    "sat_puzzles[torch.load('../data/satnet_sudoku/features.pt').sum(-1)==0]=0\n",
    "\n",
    "masks = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[sat_puzzles]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Euler_Maruyama_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can solve Sudoku with any number of attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard puzzles that are not solved in one run can be solved in multiple runs\n",
    "def rep8(sudoku0, repeat=1):\n",
    "    #generate symmetric sudokus\n",
    "    sudoku1 = sudoku0[...,::-1,:]\n",
    "    sudoku2 = sudoku0.transpose(0,2,1,3)\n",
    "    sudoku3 = sudoku0[...,::-1,:].transpose(0,2,1,3)\n",
    "    sudoku4 = sudoku0[:,::-1,:,:]\n",
    "    sudoku5 = sudoku0[:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku6 = sudoku0[...,::-1,:][:,::-1,:,:]\n",
    "    sudoku7 = sudoku0[...,::-1,:][:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku = np.concatenate([sudoku0, sudoku1,sudoku2,sudoku3,sudoku4,sudoku5,sudoku6,sudoku7], axis=0)\n",
    "    sudoku = np.repeat(sudoku, repeat, axis=0)\n",
    "    return sudoku\n",
    "\n",
    "solutions = []\n",
    "ntrys = []\n",
    "for i, q in enumerate(np.array_split(masks, masks.shape[0] // 128)):\n",
    "    mask = q\n",
    "    solution = np.zeros((mask.shape[0], 9, 9))\n",
    "\n",
    "    istrue = np.ones(mask.shape[0])==0\n",
    "    ntry = np.zeros(mask.shape[0])\n",
    "\n",
    "    while True:\n",
    "        batchsize = 512\n",
    "        n_rep = batchsize // np.sum(~istrue)\n",
    "        \n",
    "        samples = sampler(score_model,\n",
    "                            (9,9,9),\n",
    "                            mask=torch.FloatTensor(np.repeat(mask.cpu().numpy()[~istrue,:], n_rep, axis=0)).cuda(),\n",
    "                            batch_size=np.sum(~istrue) * n_rep,\n",
    "                            max_time=1,\n",
    "                            min_time=0.01,\n",
    "                            time_dilation=8,\n",
    "                            num_steps=100,\n",
    "                            random_order=False,\n",
    "                            speed_balanced=True,\n",
    "                            speed_factor=9./2.,\n",
    "                            device=device)\n",
    "        \n",
    "        acc = np.array(sudoku_acc(samples, return_array=True)).reshape((-1,n_rep))\n",
    "        \n",
    "        istrueinds = np.where(~istrue)[0]\n",
    "        for i in range(acc.shape[0]):\n",
    "            if acc[i,:].any():\n",
    "                ind = i * n_rep + np.where(acc[i,:])[0][0]\n",
    "                solution[np.where(~istrue)[0][i] - 1] = samples[ind].detach().cpu().numpy().argmax(-1) \n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + np.where(acc[i,:])[0][0] + 1\n",
    "            else:\n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + acc.shape[1]\n",
    "        istrue[~istrue] =  acc.any(axis=1)\n",
    "\n",
    "        print('correct {} %'.format(100 * np.mean(istrue)))\n",
    "        \n",
    "        if np.all(istrue):\n",
    "            print('Bingo!')\n",
    "            break\n",
    "            \n",
    "    solutions.append(solution)\n",
    "    ntrys.append(ntry)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.021875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(ntrys).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reproduce Table 2, Solution task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:02<00:00, 45.05it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.04it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.24it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.39it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.74it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.85it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.41it/s]\n",
      "100%|| 100/100 [00:02<00:00, 43.62it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.36it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.36it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.49it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.76it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.00it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.87it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.93it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.30it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.17it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.73it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.40it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.89it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.14it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.02it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.40it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.37it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.44it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.70it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.71it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.21it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.91it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.81it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.54it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.42it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.90it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.73it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.00it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.35it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.48it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.91it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.01it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.54it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.94it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.07it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.80it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.93it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.39it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.18it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.32it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.50it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.41it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.29it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.04it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.24it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.65it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.18it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.03it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.88it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.55it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.78it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.83it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.35it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.78it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.93it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.14it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.83it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.67it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.34it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.96it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.11it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.72it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.20it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.80it/s]\n",
      "100%|| 100/100 [00:02<00:00, 46.19it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.01it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.50it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.97it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.24it/s]\n",
      "100%|| 100/100 [00:02<00:00, 45.79it/s]\n",
      "100%|| 100/100 [00:02<00:00, 44.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9445981787914928 0.00623961977125068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:04<00:00, 44.91it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.28it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.37it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.94it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.48it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.35it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.71it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.94it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.10it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.76it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.69it/s]\n",
      "100%|| 200/200 [00:04<00:00, 46.79it/s]\n",
      "100%|| 200/200 [00:04<00:00, 46.80it/s]\n",
      "100%|| 200/200 [00:04<00:00, 43.63it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.71it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.75it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.42it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.47it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.36it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.20it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.04it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.52it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.90it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.05it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.35it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.83it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.47it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.55it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.59it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.21it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.50it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.17it/s]\n",
      "100%|| 200/200 [00:04<00:00, 43.97it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.35it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.06it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.33it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.53it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.94it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.55it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.07it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.57it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.98it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.64it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.74it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.36it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.19it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.63it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.19it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.52it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.56it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.39it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.01it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.11it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.92it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.55it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.26it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.50it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.24it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.01it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.02it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.77it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.42it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.01it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.82it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.88it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.24it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.85it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.03it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.82it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.88it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.17it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.99it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.62it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.96it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.46it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.06it/s]\n",
      "100%|| 200/200 [00:04<00:00, 45.50it/s]\n",
      "100%|| 200/200 [00:04<00:00, 44.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965801095706619 0.005332731024896206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:08<00:00, 44.94it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.57it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.13it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.66it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.93it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.18it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.96it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.32it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.53it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.47it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.82it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.60it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.98it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.21it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.82it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.36it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.20it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.67it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.17it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.33it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.32it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.35it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.67it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.55it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.29it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.48it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.80it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.62it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.01it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.03it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.48it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.90it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.86it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.97it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.84it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.54it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.28it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.69it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.99it/s]\n",
      "100%|| 400/400 [00:09<00:00, 44.22it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.04it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.21it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.98it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.35it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.72it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.40it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.27it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.26it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.06it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.81it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.16it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.79it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.47it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.60it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.67it/s]\n",
      "100%|| 400/400 [00:08<00:00, 45.06it/s]\n",
      "100%|| 400/400 [00:09<00:00, 44.39it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.55it/s]\n",
      "100%|| 400/400 [00:08<00:00, 44.87it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.86it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.78it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.35it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.23it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.35it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.49it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.07it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.23it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.45it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.27it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.21it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.52it/s]\n",
      "100%|| 400/400 [00:09<00:00, 42.81it/s]\n",
      "100%|| 400/400 [00:09<00:00, 44.40it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.37it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.68it/s]\n",
      "100%|| 400/400 [00:09<00:00, 44.13it/s]\n",
      "100%|| 400/400 [00:09<00:00, 44.11it/s]\n",
      "100%|| 400/400 [00:09<00:00, 43.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757014323693104 0.004614294802156774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:18<00:00, 43.31it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.49it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.00it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.40it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.08it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.46it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.35it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.57it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.06it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.17it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.80it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.69it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.63it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.40it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.01it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.52it/s]\n",
      "100%|| 800/800 [00:18<00:00, 44.00it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.34it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.62it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.78it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.78it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.60it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.71it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.61it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.79it/s]\n",
      "100%|| 800/800 [00:18<00:00, 44.08it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.86it/s]\n",
      "100%|| 800/800 [00:18<00:00, 43.77it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.57it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.58it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.82it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.82it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.16it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.40it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.79it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.84it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.89it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.65it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.93it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.61it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.53it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.67it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.34it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.02it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.18it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.10it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.35it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.55it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.61it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.31it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.72it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.31it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.58it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.25it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.32it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.45it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.00it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.93it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.16it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.62it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.46it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.51it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.21it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.46it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.33it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.53it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.87it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.92it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.80it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.08it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.50it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.07it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.42it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.40it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.96it/s]\n",
      "100%|| 800/800 [00:17<00:00, 44.99it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.61it/s]\n",
      "100%|| 800/800 [00:17<00:00, 45.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841001416219439 0.0032617707367515094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for time_dilation in [1, 2, 4, 8]:\n",
    "    acc = []\n",
    "    for i, mask in enumerate(np.array_split(masks, masks.shape[0] // 128)):\n",
    "        samples = Euler_Maruyama_sampler(score_model,\n",
    "                                            (9,9,9),\n",
    "                                            mask=mask,\n",
    "                                            batch_size=mask.shape[0],\n",
    "                                            max_time=1,\n",
    "                                            min_time=0.01,\n",
    "                                            time_dilation=time_dilation,\n",
    "                                            num_steps=100,\n",
    "                                            random_order=False,\n",
    "                                            speed_balanced=True,\n",
    "                                            speed_factor=9./2.,\n",
    "                                            device=device)\n",
    "        acc.append(np.mean(sudoku_acc(samples, return_array=True)))\n",
    "    print(np.mean(acc), np.std(acc)/np.sqrt(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961089494163424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9980544747081712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961089494163424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995136186770428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:10<00:00, 24.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961089494163424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:10<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948119325551232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:10<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9944413563090606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:10<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995136186770428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:10<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995244271508863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:09<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957198443579767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9954014856738592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957846952010376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|                                  | 2262/3200 [01:30<00:37, 25.04it/s]"
     ]
    }
   ],
   "source": [
    "sat_single_accs = []\n",
    " \n",
    "for i, mask in enumerate(np.array_split(masks, masks.shape[0] // 256)):\n",
    "    samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0], \n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=128, \n",
    "                  num_steps=25,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=True, \n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "    \n",
    "    sat_single_accs.append(sudoku_acc(samples, return_array=True))\n",
    "    print(np.mean(sat_single_accs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(sat_single_accs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard puzzles \n",
    "\n",
    "#https://github.com/rasmusbergpalm/recurrent-relational-networks/blob/master/tasks/sudoku/data.py\n",
    "class sudoku:\n",
    "    url = \"https://www.dropbox.com/s/rp3hbjs91xiqdgc/sudoku-hard.zip?dl=1\"  # See generate_hard.py on how this dataset was generated\n",
    "    zip_fname = \"/tmp/sudoku-hard.zip\"\n",
    "    dest_dir = '/tmp/sudoku-hard/'\n",
    "\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(self.dest_dir):\n",
    "            print(\"Downloading data...\")\n",
    "\n",
    "            urllib.request.urlretrieve(self.url, self.zip_fname)\n",
    "            with zipfile.ZipFile(self.zip_fname) as f:\n",
    "                f.extractall('/tmp/')\n",
    "\n",
    "        def read_csv(fname):\n",
    "            print(\"Reading %s...\" % fname)\n",
    "            with open(self.dest_dir + fname) as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                return [(q, a) for q, a in reader]\n",
    "\n",
    "        self.train = read_csv('train.csv')\n",
    "        self.valid = read_csv('valid.csv')\n",
    "        self.test = read_csv('test.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv...\n",
      "Reading valid.csv...\n",
      "Reading test.csv...\n"
     ]
    }
   ],
   "source": [
    "harddataset = sudoku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.concatenate([np.array(list(harddataset.test[i][0])).astype(np.int64).reshape((1,9,9)) for i in range(len(harddataset.test))])\n",
    "answer = np.concatenate([np.array(list(harddataset.test[i][1])).astype(np.int64).reshape((1,9,9)) for i in range(len(harddataset.test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:08<00:00, 24.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 14.0625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "score_model.eval()\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask, \n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=1,\n",
    "                  num_steps=200,\n",
    "                  random_order=False, \n",
    "                  speed_balanced=True, \n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1600/1600 [01:04<00:00, 24.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 24.21875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01, \n",
    "                  time_dilation=8,\n",
    "                  num_steps=200, \n",
    "                  random_order=False,\n",
    "                  speed_balanced=True,\n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6400/6400 [04:16<00:00, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 33.59375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=64,\n",
    "                  num_steps=100, \n",
    "                  random_order=False, \n",
    "                  speed_balanced=True,\n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12800/12800 [08:31<00:00, 25.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 34.765625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "sb = UnitStickBreakingTransform()\n",
    "device = 'cuda'\n",
    "score_model.eval()\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9), \n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=128,\n",
    "                  num_steps=100,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=True, \n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 12800/12800 [08:36<00:00, 24.77it/s]\n",
      " 34%|                                         | 4311/12800 [02:53<05:36, 25.22it/s]"
     ]
    }
   ],
   "source": [
    "single_accs = []\n",
    "for puzzle in np.array_split(query, query.shape[0]//256):\n",
    "    mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "    samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=128,\n",
    "                  num_steps=100,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=True,\n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "    \n",
    "    single_accs.append(sudoku_acc(samples, return_array=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37266666666666665"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(single_accs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036039039189176675"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(np.concatenate(single_accs))/np.sqrt(np.concatenate(single_accs).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hard puzzles that are not solved in one run can be solved in multiple runs\n",
    "#this is too slow to run on one node. use slurm\n",
    "def rep8(sudoku0, repeat=1):\n",
    "    #generate symmetric sudokus\n",
    "    sudoku1 = sudoku0[...,::-1,:]\n",
    "    sudoku2 = sudoku0.transpose(0,2,1,3)\n",
    "    sudoku3 = sudoku0[...,::-1,:].transpose(0,2,1,3)\n",
    "    sudoku4 = sudoku0[:,::-1,:,:]\n",
    "    sudoku5 = sudoku0[:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku6 = sudoku0[...,::-1,:][:,::-1,:,:]\n",
    "    sudoku7 = sudoku0[...,::-1,:][:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku = np.concatenate([sudoku0, sudoku1,sudoku2,sudoku3,sudoku4,sudoku5,sudoku6,sudoku7], axis=0)\n",
    "    sudoku = np.repeat(sudoku, repeat, axis=0)\n",
    "    return sudoku\n",
    "\n",
    "query = np.concatenate([np.array(list(harddataset.test[i][0])).astype(np.int64).reshape((1,9,9)) for i in range(len(harddataset.test))])\n",
    "solutions = []\n",
    "ntrys = []\n",
    "\n",
    "for i, q in enumerate(np.array_split(query, query.shape[0]//128)):\n",
    "    puzzle = q\n",
    "    mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "    solution = np.zeros((puzzle.shape[0], 9, 9))\n",
    "    istrue = np.ones(mask.shape[0])==0\n",
    "    ntry = np.zeros(mask.shape[0])\n",
    "\n",
    "    while True:\n",
    "        batchsize = 512\n",
    "        n_rep = batchsize // np.sum(~istrue)\n",
    "        samples = sampler(score_model,\n",
    "                      (9,9,9),\n",
    "                      mask= torch.FloatTensor(np.repeat(mask.cpu().numpy()[~istrue,:], n_rep, axis=0)).cuda(),\n",
    "                      batch_size=np.sum(~istrue) * n_rep,\n",
    "                      max_time=1,\n",
    "                      min_time=0.01,\n",
    "                      time_dilation=8,\n",
    "                      num_steps=200,\n",
    "                      random_order=False,\n",
    "                      speed_balanced=True,\n",
    "                      device=device)\n",
    "        \n",
    "        acc = np.array(sudoku_acc(samples, return_array=True)).reshape((-1,n_rep))\n",
    "        \n",
    "        istrueinds = np.where(~istrue)[0]\n",
    "        for i in range(acc.shape[0]):\n",
    "            if acc[i,:].any():\n",
    "                ind = i * n_rep + np.where(acc[i,:])[0][0]\n",
    "                solution[np.where(~istrue)[0][i]] = samples[ind].detach().cpu().numpy().argmax(-1) \n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + np.where(acc[i,:])[0] + 1\n",
    "            else:\n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + acc.shape[1]\n",
    "        istrue[~istrue] =  acc.any(axis=1)\n",
    "\n",
    "        print('correct {} %'.format(100 * np.mean(istrue)))\n",
    "        if np.all(istrue):\n",
    "            print('Bingo!')\n",
    "            break\n",
    "    solutions.append(solution)\n",
    "    ntrys.append(ntry)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((query[:1548,:,:]!=0).sum(axis=-1).sum(axis=-1), np.log10(np.concatenate(ntrys)),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "require(scales)\n",
    "theme_Publication <- function(base_size=14, base_family=\"helvetica\") {\n",
    "      library(grid)\n",
    "      library(ggthemes)\n",
    "      (theme_foundation(base_size=base_size, base_family=base_family)\n",
    "       + theme(plot.title = element_text(face = \"bold\",\n",
    "                                         size = rel(1.2), hjust = 0.5),\n",
    "               text = element_text(),\n",
    "               panel.background = element_rect(colour = NA),\n",
    "               plot.background = element_rect(colour = NA),\n",
    "               panel.border = element_rect(colour = NA),\n",
    "               axis.title = element_text(face = \"bold\",size = rel(1)),\n",
    "               axis.title.y = element_text(angle=90,vjust =2),\n",
    "               axis.title.x = element_text(vjust = -0.2),\n",
    "               axis.text = element_text(), \n",
    "               axis.line = element_line(colour=\"black\"),\n",
    "               axis.ticks = element_line(),\n",
    "               panel.grid.major = element_blank(),\n",
    "               panel.grid.minor = element_blank(),\n",
    "               legend.key = element_rect(colour = NA),\n",
    "               legend.position = \"bottom\",\n",
    "               legend.direction = \"horizontal\",\n",
    "               legend.key.size= unit(1, \"cm\"),\n",
    "               legend.margin = unit(0, \"cm\"),\n",
    "               legend.title = element_text(face=\"italic\"),\n",
    "               plot.margin=unit(c(10,5,5,5),\"mm\"),\n",
    "               strip.background=element_rect(colour=\"#f0f0f0\",fill=\"#f0f0f0\"),\n",
    "               strip.text = element_text(face=\"bold\")\n",
    "          ))\n",
    "      \n",
    "}\n",
    "scale_fill_Publication <- function(...){\n",
    "      discrete_scale(\"fill\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\")), ...)\n",
    "\n",
    "}\n",
    "scale_colour_Publication <- function(...){\n",
    "      discrete_scale(\"colour\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\")), ...)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((solutions, ntrys, ngiven), './hard_sudoku.solutions.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.log10(ntrys[ngiven==24])), np.median(np.log10(ntrys[ngiven==17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i ngiven,ntrys -w 5 -h 3 --unit in --res 300\n",
    "require(ggplot2)\n",
    "ggplot()+geom_boxplot(aes(x=factor(ngiven, levels= seq(34,17,-1)), y=log10(ntrys)), outlier.shape=NA)+\n",
    "    theme_Publication()+xlab('# of clues given')+ylab('# of samples needed to solve \\n (log10)')\n",
    "ggsave('./figures/hard_sudoku_scaling.pdf', device=cairo_pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_ml",
   "language": "python",
   "name": "pytorch_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
