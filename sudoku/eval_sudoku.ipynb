{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Evaluaing Sudoku Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import functools\n",
    "import random, copy\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from ddsm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load presampled noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_one, v_zero, v_one_loggrad, v_zero_loggrad, timepoints = torch.load('steps400.cat9.time1.0.samples100000.pth')\n",
    "torch.set_default_dtype(torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aae319951c0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(v_one[:,-1,0].detach().cpu(), v_one_loggrad[:,-1,0].detach().cpu(),'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define several functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_puzzle_solution():\n",
    "    \"\"\"\n",
    "    Randomly arrange numbers in a grid while making all rows, columns and\n",
    "    squares (sub-grids) contain the numbers 1 through 9.\n",
    "    For example, \"sample\" (above) could be the output of this function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop until we're able to fill all 81 cells with numbers, while\n",
    "    # satisfying the constraints above.\n",
    "    while True:\n",
    "        try:\n",
    "            puzzle  = [[0]*9 for i in range(9)] # start with blank puzzle\n",
    "            rows    = [set(range(1,10)) for i in range(9)] # set of available\n",
    "            columns = [set(range(1,10)) for i in range(9)] #   numbers for each\n",
    "            squares = [set(range(1,10)) for i in range(9)] #   row, column and square\n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    # pick a number for cell (i,j) from the set of remaining available numbers\n",
    "                    choices = rows[i].intersection(columns[j]).intersection(squares[(i//3)*3 + j//3])\n",
    "                    choice  = random.choice(list(choices))\n",
    "        \n",
    "                    puzzle[i][j] = choice\n",
    "        \n",
    "                    rows[i].discard(choice)\n",
    "                    columns[j].discard(choice)\n",
    "                    squares[(i//3)*3 + j//3].discard(choice)\n",
    "\n",
    "            # success! every cell is filled.\n",
    "            return puzzle\n",
    "            \n",
    "        except IndexError:\n",
    "            # if there is an IndexError, we have worked ourselves in a corner (we just start over)\n",
    "            pass\n",
    "\n",
    "def pluck(puzzle, n=0):\n",
    "\n",
    "    \"\"\"\n",
    "    Randomly pluck out cells (numbers) from the solved puzzle grid, ensuring that any\n",
    "    plucked number can still be deduced from the remaining cells.\n",
    "    For deduction to be possible, each other cell in the plucked number's row, column,\n",
    "    or square must not be able to contain that number.\n",
    "\n",
    "    Answers the question: can the cell (i,j) in the puzzle \"puz\" contain the number\n",
    "    in cell \"c\"? \"\"\"\n",
    "    def canBeA(puz, i, j, c):\n",
    "        v = puz[c//9][c%9]\n",
    "        if puz[i][j] == v: return True\n",
    "        if puz[i][j] in range(1,10): return False\n",
    "            \n",
    "        for m in range(9): # test row, col, square\n",
    "            # if not the cell itself, and the mth cell of the group contains the value v, then \"no\"\n",
    "            if not (m==c//9 and j==c%9) and puz[m][j] == v: return False\n",
    "            if not (i==c//9 and m==c%9) and puz[i][m] == v: return False\n",
    "            if not ((i//3)*3 + m//3==c//9 and (j//3)*3 + m%3==c%9) and puz[(i//3)*3 + m//3][(j//3)*3 + m%3] == v:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    starts with a set of all 81 cells, and tries to remove one (randomly) at a time\n",
    "    but not before checking that the cell can still be deduced from the remaining cells. \"\"\"\n",
    "    cells     = set(range(81))\n",
    "    cellsleft = cells.copy()\n",
    "    while len(cells) > n and len(cellsleft):\n",
    "        cell = random.choice(list(cellsleft)) # choose a cell from ones we haven't tried\n",
    "        cellsleft.discard(cell) # record that we are trying this cell\n",
    "\n",
    "        # row, col and square record whether another cell in those groups could also take\n",
    "        # on the value we are trying to pluck. (If another cell can, then we can't use the\n",
    "        # group to deduce this value.) If all three groups are True, then we cannot pluck\n",
    "        # this cell and must try another one.\n",
    "        row = col = square = False\n",
    "\n",
    "        for i in range(9):\n",
    "            if i != cell//9:\n",
    "                if canBeA(puzzle, i, cell%9, cell): row = True\n",
    "            if i != cell%9:\n",
    "                if canBeA(puzzle, cell//9, i, cell): col = True\n",
    "            if not (((cell//9)//3)*3 + i//3 == cell//9 and ((cell//9)%3)*3 + i%3 == cell%9):\n",
    "                if canBeA(puzzle, ((cell//9)//3)*3 + i//3, ((cell//9)%3)*3 + i%3, cell): square = True\n",
    "\n",
    "        if row and col and square:\n",
    "            continue # could not pluck this cell, try again.\n",
    "        else:\n",
    "            # this is a pluckable cell!\n",
    "            puzzle[cell//9][cell%9] = 0 # 0 denotes a blank cell\n",
    "            cells.discard(cell) # remove from the set of visible cells (pluck it)\n",
    "            # we don't need to reset \"cellsleft\" because if a cell was not pluckable\n",
    "            # earlier, then it will still not be pluckable now (with less information\n",
    "            # on the board).\n",
    "\n",
    "    # This is the puzzle we found, in all its glory.\n",
    "    return (puzzle, len(cells))\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "That's it.\n",
    "If we want to make a puzzle we can do this:\n",
    "    pluck(construct_puzzle_solution())\n",
    "    \n",
    "The following functions are convenience functions for doing just that...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This uses the above functions to create a new puzzle. It attempts to\n",
    "create one with 28 (by default) given cells, but if it can't, it returns\n",
    "one with as few givens as it is able to find.\n",
    "This function actually tries making 100 puzzles (by default) and returns\n",
    "all of them. The \"best\" function that follows this one selects the best\n",
    "one of those.\n",
    "\"\"\"\n",
    "def run(n = 28, iter=100):\n",
    "    all_results = {}\n",
    "#     print \"Constructing a sudoku puzzle.\"\n",
    "#     print \"* creating the solution...\"\n",
    "    a_puzzle_solution = construct_puzzle_solution()\n",
    "    \n",
    "#     print \"* constructing a puzzle...\"\n",
    "    for i in range(iter):\n",
    "        puzzle = copy.deepcopy(a_puzzle_solution)\n",
    "        (result, number_of_cells) = pluck(puzzle, n)\n",
    "        all_results.setdefault(number_of_cells, []).append(result)\n",
    "        if number_of_cells <= n: break\n",
    " \n",
    "    return all_results, a_puzzle_solution\n",
    "\n",
    "def best(set_of_puzzles):\n",
    "    # Could run some evaluation function here. For now just pick\n",
    "    # the one with the fewest \"givens\".\n",
    "    return set_of_puzzles[min(set_of_puzzles.keys())][0]\n",
    "\n",
    "def display(puzzle):\n",
    "    for row in puzzle:\n",
    "        print(' '.join([str(n or '_') for n in row]))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def gen_sudoku(num):\n",
    "    '''\n",
    "    Generates `num` games of Sudoku.\n",
    "    '''\n",
    "    solutions = np.zeros((num, 9, 9), np.int32)\n",
    "    for i in range(num):\n",
    "        solutions[i] = construct_puzzle_solution()\n",
    "\n",
    "    return solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_puzzle_solution_successrate(total_success):\n",
    "    # Loop until we're able to fill all 81 cells with numbers, while\n",
    "    # satisfying the constraints above.\n",
    "    nfailure=0\n",
    "    nsuccess=0\n",
    "    while nsuccess<total_success:\n",
    "        try:\n",
    "            puzzle  = [[0]*9 for i in range(9)] # start with blank puzzle\n",
    "            rows    = [set(range(1,10)) for i in range(9)] # set of available\n",
    "            columns = [set(range(1,10)) for i in range(9)] #   numbers for each\n",
    "            squares = [set(range(1,10)) for i in range(9)] #   row, column and square\n",
    "            for i in range(9):\n",
    "                for j in range(9):\n",
    "                    # pick a number for cell (i,j) from the set of remaining available numbers\n",
    "                    choices = rows[i].intersection(columns[j]).intersection(squares[(i//3)*3 + j//3])\n",
    "                    choice  = random.choice(list(choices))\n",
    "        \n",
    "                    puzzle[i][j] = choice\n",
    "        \n",
    "                    rows[i].discard(choice)\n",
    "                    columns[j].discard(choice)\n",
    "                    squares[(i//3)*3 + j//3].discard(choice)\n",
    "\n",
    "            # success! every cell is filled.\n",
    "            nsuccess += 1\n",
    "            \n",
    "        except IndexError:\n",
    "            print('fail')\n",
    "            nfailure += 1\n",
    "            pass\n",
    "    return nsuccess / nfailure\n",
    "#construct_puzzle_solution(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check sudoku correctness\n",
    "def sudoku_acc(sample, return_array=False):\n",
    "    sample = sample.detach().cpu().numpy()\n",
    "    correct = 0\n",
    "    total = sample.shape[0]\n",
    "    ans = sample.argmax(-1)+1\n",
    "    numbers_1_N = np.arange(1, 9 + 1)\n",
    "    corrects = []\n",
    "    for board in ans:\n",
    "        if (np.all(np.sort(board, axis=1) == numbers_1_N) and\n",
    "            np.all(np.sort(board.T, axis=1) == numbers_1_N)):\n",
    "            # Check blocks\n",
    "            \n",
    "            blocks = board.reshape(3, 3, 3, 3).transpose(0, 2, 1, 3).reshape(9, 9)\n",
    "            if np.all(np.sort(board.T, axis=1) == numbers_1_N):\n",
    "                correct += 1\n",
    "                corrects.append(True)\n",
    "            else:\n",
    "                corrects.append(False)\n",
    "        else:\n",
    "            corrects.append(False)\n",
    "\n",
    "    if return_array:\n",
    "        return corrects\n",
    "    else:\n",
    "        print('correct {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "colind = np.array([[0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8],\n",
    "            [0,1,2,3,4,5,6,7,8]])\n",
    "\n",
    "rowind = np.array([[0,0,0,0,0,0,0,0,0],\n",
    "          [1,1,1,1,1,1,1,1,1],\n",
    "          [2,2,2,2,2,2,2,2,2],\n",
    "          [3,3,3,3,3,3,3,3,3],\n",
    "          [4,4,4,4,4,4,4,4,4],\n",
    "          [5,5,5,5,5,5,5,5,5],\n",
    "          [6,6,6,6,6,6,6,6,6],\n",
    "          [7,7,7,7,7,7,7,7,7],\n",
    "          [8,8,8,8,8,8,8,8,8]])\n",
    "\n",
    "\n",
    "blockind = np.array([[0,0,0,1,1,1,2,2,2],\n",
    "          [0,0,0,1,1,1,2,2,2],\n",
    "          [0,0,0,1,1,1,2,2,2],\n",
    "          [3,3,3,4,4,4,5,5,5],\n",
    "          [3,3,3,4,4,4,5,5,5],\n",
    "          [3,3,3,4,4,4,5,5,5],\n",
    "          [6,6,6,7,7,7,8,8,8],\n",
    "          [6,6,6,7,7,7,8,8,8],\n",
    "          [6,6,6,7,7,7,8,8,8]])\n",
    "\n",
    "colenc = np.zeros((81,9))\n",
    "rowenc = np.zeros((81,9))\n",
    "blockenc = np.zeros((81,9))\n",
    "colenc[np.arange(81),colind.flatten()] = 1\n",
    "rowenc[np.arange(81),rowind.flatten()] = 1\n",
    "blockenc[np.arange(81),blockind.flatten()] = 1\n",
    "allenc = np.concatenate([colenc, rowenc, blockenc], axis=1)\n",
    "allenc_relative = torch.FloatTensor(allenc[:,None,:]==allenc[None,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sudoku dataloader that generate sudoku in real-time\n",
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return int(batchSize*1000)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sudoku = gen_sudoku(1)\n",
    "        dataset = np.eye(9)[sudoku.reshape(sudoku.shape[0],-1)-1]\n",
    "        return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate time dependent weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importance sampling weights \n",
    "#this part may change, no need to spend too much time on understanding it\n",
    "device = 'cuda'\n",
    "batchSize = 256 \n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(worker_id)\n",
    "\n",
    "sb = UnitStickBreakingTransform()\n",
    "ds = SudokuDataset()\n",
    "train_dataloader = DataLoader(ds, batchSize, shuffle=True, num_workers=16, worker_init_fn=worker_init_fn)\n",
    "\n",
    "time_dependent_cums = torch.zeros(timepoints.shape[0]).to(device)\n",
    "time_dependent_counts = torch.zeros(timepoints.shape[0]).to(device)\n",
    "\n",
    "avg_loss = 0.\n",
    "num_items = 0\n",
    "for i, x in enumerate(train_dataloader):\n",
    "    x = x.reshape(-1,9,9,9)\n",
    "    random_t = torch.randint(0, timepoints.shape[0], (x.shape[0],))\n",
    "    order = np.random.permutation(np.arange(9))\n",
    "    #perturbed_x, perturbed_x_grad = diffusion_factory(x[...,order], random_t,  v_one, v_zero,v_one_loggrad, v_zero_loggrad, alpha, beta)\n",
    "    perturbed_x, perturbed_x_grad = diffusion_fast_flatdirichlet(x[...,order], random_t, v_one, v_one_loggrad)\n",
    "    perturbed_x = perturbed_x[..., np.argsort(order)]\n",
    "    perturbed_x_grad = perturbed_x_grad[..., np.argsort(order)]\n",
    "    perturbed_x = perturbed_x.to(device)    \n",
    "    perturbed_x_grad = perturbed_x_grad.to(device)\n",
    "    random_t = random_t.to(device)\n",
    "    perturbed_v = sb._inverse(perturbed_x)\n",
    "\n",
    "    \n",
    "    order = np.random.permutation(np.arange(9))\n",
    "    perturbed_v = sb._inverse(perturbed_x[..., order], prevent_nan=True).detach()\n",
    "\n",
    "    time_dependent_counts[random_t] += 1\n",
    "    #time_dependent_cums[random_t] +=  ( ((perturbed_x)*(1-perturbed_x))**2 * (perturbed_x_grad)**2).mean(dim=(1,2,3)).detach()\n",
    "    time_dependent_cums[random_t] +=  (perturbed_v*(1-perturbed_v) * (gx_to_gv(perturbed_x_grad[...,order],perturbed_x[...,order]))**2).mean(dim=(1,2,3)).detach()\n",
    "    time_dependent_weights =  time_dependent_cums / time_dependent_counts\n",
    "    time_dependent_weights = time_dependent_weights / time_dependent_weights.mean()\n",
    "    \n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2aaab60faac0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time_dependent_weights.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modified from minGPT \n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "class NewGELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n",
    "    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
    "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
    "    explicit implementation here to show that there is nothing too scary here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, bias=None):\n",
    "        super().__init__()\n",
    "        assert n_embd % n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(n_embd, 3 * n_embd)\n",
    "        self.c_proj = nn.Linear(n_embd, n_embd)\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.n_embd = n_embd\n",
    "        self.register_buffer(\"bias\",bias)\n",
    "        \n",
    "        self.bias_proj = nn.Linear(bias.shape[-1], n_head) #T, T, nh\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        att = att + self.bias_proj(self.bias).permute((2,0,1))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "        #att = self.attn_dropout(att)\n",
    "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.c_proj(y)\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" an unassuming Transformer block \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, bias=None):\n",
    "        super().__init__()\n",
    "        self.ln_1 = nn.LayerNorm(n_embd)\n",
    "        self.attn = SelfAttention(n_embd, n_head, bias=bias)\n",
    "        self.ln_2 = nn.LayerNorm(n_embd)\n",
    "        self.mlp = nn.ModuleDict(dict(\n",
    "            c_fc    = nn.Linear(n_embd, 4 * n_embd),\n",
    "            c_proj  = nn.Linear(4 * n_embd, n_embd),\n",
    "            act     = NewGELU(),\n",
    "        ))\n",
    "        m = self.mlp\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp.c_proj(self.mlp.act(self.mlp.c_fc(self.ln_2(x))))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Gaussian random features for encoding time steps.\n",
    "    \"\"\"  \n",
    "    \n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    A fully connected layer that reshapes outputs to feature maps.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)[...]\n",
    "\n",
    "    \n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, allenc_rel, embed_dim=256, ):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    \n",
    "    self.linear = Dense(9,128)\n",
    "    self.blocks = nn.ModuleList(Block(128, 8, bias=allenc_rel) for _ in range(20))\n",
    "    self.denses = nn.ModuleList(Dense(embed_dim, 128) for _ in range(20))\n",
    "    self.act = NewGELU()\n",
    "    self.softplus = nn.Softplus()\n",
    "    self.output = Dense(128,9)\n",
    "    self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "  \n",
    "  def forward(self, x, t): \n",
    "    # Obtain the Gaussian random feature embedding for t   \n",
    "    embed = self.act(self.embed(t))\n",
    "    \n",
    "    # Encoding path\n",
    "    h =   self.linear(x.view(-1,81,9))\n",
    "    for le, ld in zip(self.blocks, self.denses):\n",
    "        h = le(h + ld(embed)[:,None,:])\n",
    "\n",
    "    h = self.output(h)\n",
    "\n",
    "    #h = h.reshape(x.size()) * torch.exp(-t[:,None,None,None]* self.softplus(self.scale)) /  ((x+1e-6)*(1-x+1e-6))\n",
    "    h = h.reshape(x.size()) #* torch.exp(-t[:,None,None,None]* self.softplus(self.scale)) * (1/(x+1e-3)+1/(1-x+1e-3))\n",
    "    h = h - h.mean(axis=-1, keepdims=True)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ScoreNet(\n",
       "    (embed): Sequential(\n",
       "      (0): GaussianFourierProjection()\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear): Dense(\n",
       "      (dense): Linear(in_features=9, out_features=128, bias=True)\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (12): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (13): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (14): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (15): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (16): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (17): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (18): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "      (19): Block(\n",
       "        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): SelfAttention(\n",
       "          (c_attn): Linear(in_features=128, out_features=384, bias=True)\n",
       "          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (bias_proj): Linear(in_features=27, out_features=8, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): ModuleDict(\n",
       "          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (act): NewGELU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (denses): ModuleList(\n",
       "      (0): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (1): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (2): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (3): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (4): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (5): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (6): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (7): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (8): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (9): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (10): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (11): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (12): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (13): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (14): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (15): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (16): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (17): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (18): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "      (19): Dense(\n",
       "        (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (act): NewGELU()\n",
       "    (softplus): Softplus(beta=1, threshold=20)\n",
       "    (output): Dense(\n",
       "      (dense): Linear(in_features=128, out_features=9, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = nn.DataParallel(ScoreNet(allenc_relative))\n",
    "score_model.module.load_state_dict(torch.load('../best_model_weights/sudoku/sudoku.transformer.pth'))\n",
    "score_model = score_model.to('cuda')\n",
    "score_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:36<00:00, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device='cuda'\n",
    "score_model.eval()\n",
    "acc = []\n",
    "samples = Euler_Maruyama_sampler(score_model,\n",
    "                  (9,9,9), \n",
    "                  batch_size=256,\n",
    "                  max_time=1, \n",
    "                  min_time=0.01,\n",
    "                  time_dilation=8,\n",
    "                  num_steps=100,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=False,\n",
    "                  device=device)\n",
    "acc.append(sudoku_acc(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "Generate results for table 2 - Sudoku Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:03<00:00, 25.26it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.29it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.09it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.36it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.30it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.16it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.14it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.16it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.31it/s]\n",
      "100%|| 100/100 [00:03<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946875 0.003737682316251907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:07<00:00, 25.30it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.32it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.26it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.26it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.25it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.31it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.18it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.14it/s]\n",
      "100%|| 200/200 [00:07<00:00, 25.03it/s]\n",
      "100%|| 200/200 [00:08<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9890625 0.001727408744976771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:16<00:00, 24.83it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.11it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.16it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.40it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.26it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.21it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.18it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.24it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.21it/s]\n",
      "100%|| 400/400 [00:15<00:00, 25.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999609375 0.0003906250000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:31<00:00, 25.26it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.28it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.25it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.09it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.05it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.04it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.10it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.18it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.22it/s]\n",
      "100%|| 800/800 [00:31<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for time_dilation in [1, 2, 4, 8]:\n",
    "    acc = []\n",
    "    for i in range(10):\n",
    "        score_model.eval()\n",
    "        samples = Euler_Maruyama_sampler(score_model,\n",
    "                          (9,9,9),\n",
    "                          batch_size=256,\n",
    "                          max_time=1,\n",
    "                          min_time=0.01,\n",
    "                          time_dilation=time_dilation,\n",
    "                          num_steps=100,\n",
    "                          random_order=False,\n",
    "                          speed_balanced=True,\n",
    "                          speed_factor=9./2., \n",
    "                          device=device)\n",
    "        acc.append(np.mean(sudoku_acc(samples, return_array=True)))\n",
    "    print(np.mean(acc), np.std(acc)/np.sqrt(9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving SatNet Puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#satnet puzzles\n",
    "sat_puzzles = torch.load('../data/satnet_sudoku/features.pt').argmax(-1) + 1\n",
    "sat_puzzles[torch.load('../data/satnet_sudoku/features.pt').sum(-1)==0]=0\n",
    "\n",
    "masks = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[sat_puzzles]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Euler_Maruyama_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we can solve Sudoku with any number of attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:45<00:00, 17.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:45<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:45<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:45<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 99.2248062015504 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:45<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:46<00:00, 17.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [01:00<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|                                                               | 42/800 [00:03<00:55, 13.61it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|| 800/800 [00:59<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [01:00<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [01:00<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [01:00<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [01:00<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 800/800 [00:59<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 100.0 %\n",
      "Bingo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 794/800 [00:59<00:00, 13.78it/s]"
     ]
    }
   ],
   "source": [
    "#hard puzzles that are not solved in one run can be solved in multiple runs\n",
    "def rep8(sudoku0, repeat=1):\n",
    "    #generate symmetric sudokus\n",
    "    sudoku1 = sudoku0[...,::-1,:]\n",
    "    sudoku2 = sudoku0.transpose(0,2,1,3)\n",
    "    sudoku3 = sudoku0[...,::-1,:].transpose(0,2,1,3)\n",
    "    sudoku4 = sudoku0[:,::-1,:,:]\n",
    "    sudoku5 = sudoku0[:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku6 = sudoku0[...,::-1,:][:,::-1,:,:]\n",
    "    sudoku7 = sudoku0[...,::-1,:][:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku = np.concatenate([sudoku0, sudoku1,sudoku2,sudoku3,sudoku4,sudoku5,sudoku6,sudoku7], axis=0)\n",
    "    sudoku = np.repeat(sudoku, repeat, axis=0)\n",
    "    return sudoku\n",
    "\n",
    "solutions = []\n",
    "ntrys = []\n",
    "for i, q in enumerate(np.array_split(masks, masks.shape[0] // 128)):\n",
    "    mask = q\n",
    "    solution = np.zeros((mask.shape[0], 9, 9))\n",
    "\n",
    "    istrue = np.ones(mask.shape[0])==0\n",
    "    ntry = np.zeros(mask.shape[0])\n",
    "\n",
    "    while True:\n",
    "        batchsize = 512\n",
    "        n_rep = batchsize // np.sum(~istrue)\n",
    "        \n",
    "        samples = sampler(score_model,\n",
    "                            (9,9,9),\n",
    "                            mask=torch.FloatTensor(np.repeat(mask.cpu().numpy()[~istrue,:], n_rep, axis=0)).cuda(),\n",
    "                            batch_size=np.sum(~istrue) * n_rep,\n",
    "                            max_time=1,\n",
    "                            min_time=0.01,\n",
    "                            time_dilation=8,\n",
    "                            num_steps=100,\n",
    "                            random_order=False,\n",
    "                            speed_balanced=True,\n",
    "                            speed_factor=9./2.,\n",
    "                            device=device)\n",
    "        \n",
    "        acc = np.array(sudoku_acc(samples, return_array=True)).reshape((-1,n_rep))\n",
    "        \n",
    "        istrueinds = np.where(~istrue)[0]\n",
    "        for i in range(acc.shape[0]):\n",
    "            if acc[i,:].any():\n",
    "                ind = i * n_rep + np.where(acc[i,:])[0][0]\n",
    "                solution[np.where(~istrue)[0][i] - 1] = samples[ind].detach().cpu().numpy().argmax(-1) \n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + np.where(acc[i,:])[0][0] + 1\n",
    "            else:\n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + acc.shape[1]\n",
    "        istrue[~istrue] =  acc.any(axis=1)\n",
    "\n",
    "        print('correct {} %'.format(100 * np.mean(istrue)))\n",
    "        \n",
    "        if np.all(istrue):\n",
    "            print('Bingo!')\n",
    "            break\n",
    "            \n",
    "    solutions.append(solution)\n",
    "    ntrys.append(ntry)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0198"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(ntrys).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reproduce Table 2, Solution task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_dilation in [1, 2, 4, 8]:\n",
    "    acc = []\n",
    "    for i, mask in enumerate(np.array_split(masks, masks.shape[0] // 128)):\n",
    "        samples = Euler_Maruyama_sampler(score_model,\n",
    "                                            (9,9,9),\n",
    "                                            mask=mask,\n",
    "                                            batch_size=mask.shape[0],\n",
    "                                            max_time=1,\n",
    "                                            min_time=0.01,\n",
    "                                            time_dilation=time_dilation,\n",
    "                                            num_steps=100,\n",
    "                                            random_order=False,\n",
    "                                            speed_balanced=True,\n",
    "                                            speed_factor=9./2.,\n",
    "                                            device=device)\n",
    "        acc.append(np.mean(sudoku_acc(samples, return_array=True)))\n",
    "    print(np.mean(acc), np.std(acc)/np.sqrt(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9922178988326849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961089494163424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948119325551232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941634241245136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9929961089494164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993514915693904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9938854919399667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9931906614785992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926502377864246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933852140077821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9929253625751681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993514915693904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9940137683328345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9944413563090606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9945525291828794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9948929961089494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05882353 0.05882353 0.05882353 ... 0.05882353 0.05882353 0.05882353]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05555556 0.05555556 0.05555556 ... 0.05555556 0.05555556 0.05555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05263158 0.05263158 0.05263158 ... 0.05263158 0.05263158 0.05263158]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05 0.05 0.05 ... 0.05 0.05 0.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04761905 0.04761905 0.04761905 ... 0.04761905 0.04761905 0.04761905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04545455 0.04545455 0.04545455 ... 0.04545455 0.04545455 0.04545455]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04347826 0.04347826 0.04347826 ... 0.04347826 0.04347826 0.04347826]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04166667 0.04166667 0.04166667 ... 0.04166667 0.04166667 0.04166667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04 0.04 0.04 ... 0.04 0.04 0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03846154 0.03846154 0.03846154 ... 0.03846154 0.03846154 0.03846154]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03703704 0.03703704 0.03703704 ... 0.03703704 0.03703704 0.03703704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03571429 0.03571429 0.03571429 ... 0.03571429 0.03571429 0.03571429]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03448276 0.03448276 0.03448276 ... 0.03448276 0.03448276 0.03448276]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03333333 0.03333333 0.03333333 ... 0.03333333 0.03333333 0.03333333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03225806 0.03225806 0.03225806 ... 0.03225806 0.03225806 0.03225806]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03125 0.03125 0.03125 ... 0.03125 0.03125 0.03125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03030303 0.03030303 0.03030303 ... 0.03030303 0.03030303 0.03030303]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02941176 0.02941176 0.02941176 ... 0.02941176 0.02941176 0.02941176]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02857143 0.02857143 0.02857143 ... 0.02857143 0.02857143 0.02857143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02777778 0.02777778 0.02777778 ... 0.02777778 0.02777778 0.02777778]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:08<00:00, 24.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02702703 0.02702703 0.02702703 ... 0.02702703 0.02702703 0.02702703]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02631579 0.02631579 0.02631579 ... 0.02631579 0.02631579 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3200/3200 [02:07<00:00, 25.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02564103 0.02564103 0.02564103 ... 0.02564103 0.02564103 0.02564103]\n"
     ]
    }
   ],
   "source": [
    "sat_single_accs = []\n",
    " \n",
    "for i, mask in enumerate(np.array_split(masks, masks.shape[0] // 256)):\n",
    "    samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0], \n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=128, \n",
    "                  num_steps=25,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=True, \n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "    \n",
    "    sat_single_accs.append(sudoku_acc(samples, return_array=True))\n",
    "    print(np.mean(sat_single_accs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(sat_single_accs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Puzzles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard puzzles \n",
    "\n",
    "#https://github.com/rasmusbergpalm/recurrent-relational-networks/blob/master/tasks/sudoku/data.py\n",
    "class sudoku:\n",
    "    url = \"https://www.dropbox.com/s/rp3hbjs91xiqdgc/sudoku-hard.zip?dl=1\"  # See generate_hard.py on how this dataset was generated\n",
    "    zip_fname = \"/tmp/sudoku-hard.zip\"\n",
    "    dest_dir = '/tmp/sudoku-hard/'\n",
    "\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(self.dest_dir):\n",
    "            print(\"Downloading data...\")\n",
    "\n",
    "            urllib.request.urlretrieve(self.url, self.zip_fname)\n",
    "            with zipfile.ZipFile(self.zip_fname) as f:\n",
    "                f.extractall('/tmp/')\n",
    "\n",
    "        def read_csv(fname):\n",
    "            print(\"Reading %s...\" % fname)\n",
    "            with open(self.dest_dir + fname) as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                return [(q, a) for q, a in reader]\n",
    "\n",
    "        self.train = read_csv('train.csv')\n",
    "        self.valid = read_csv('valid.csv')\n",
    "        self.test = read_csv('test.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv...\n",
      "Reading valid.csv...\n",
      "Reading test.csv...\n"
     ]
    }
   ],
   "source": [
    "harddataset = sudoku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.concatenate([np.array(list(harddataset.test[i][0])).astype(np.int64).reshape((1,9,9)) for i in range(len(harddataset.test))])\n",
    "answer = np.concatenate([np.array(list(harddataset.test[i][1])).astype(np.int64).reshape((1,9,9)) for i in range(len(harddataset.test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:07<00:00, 25.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 9.765625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "score_model.eval()\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask, \n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=1,\n",
    "                  num_steps=200,\n",
    "                  random_order=False, \n",
    "                  speed_balanced=True, \n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1600/1600 [01:03<00:00, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 20.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01, \n",
    "                  time_dilation=8,\n",
    "                  num_steps=200, \n",
    "                  random_order=False,\n",
    "                  speed_balanced=True,\n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6400/6400 [04:15<00:00, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 36.328125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=64,\n",
    "                  num_steps=100, \n",
    "                  random_order=False, \n",
    "                  speed_balanced=True,\n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6400/6400 [04:19<00:00, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 36.71875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "puzzle = query[:256]\n",
    "mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "sb = UnitStickBreakingTransform()\n",
    "device = 'cuda'\n",
    "score_model.eval()\n",
    "samples = sampler(score_model,\n",
    "                  (9,9,9), \n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=128,\n",
    "                  num_steps=50,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=True, \n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "sudoku_acc(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|                                                                                                 | 1008/6400 [00:41<03:39, 24.57it/s]"
     ]
    }
   ],
   "source": [
    "single_accs = []\n",
    "for puzzle in np.array_split(query, query.shape[0]//256):\n",
    "    mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "    samples = sampler(score_model,\n",
    "                  (9,9,9),\n",
    "                  mask=mask,\n",
    "                  batch_size=mask.shape[0],\n",
    "                  max_time=1,\n",
    "                  min_time=0.01,\n",
    "                  time_dilation=128,\n",
    "                  num_steps=50,\n",
    "                  random_order=False,\n",
    "                  speed_balanced=True,\n",
    "                  speed_factor=9./2.,\n",
    "                  device=device)\n",
    "    \n",
    "    single_accs.append(sudoku_acc(samples, return_array=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(single_accs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(np.concatenate(single_accs))/np.sqrt(np.concatenate(single_accs).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hard puzzles that are not solved in one run can be solved in multiple runs\n",
    "#this is too slow to run on one node. use slurm\n",
    "def rep8(sudoku0, repeat=1):\n",
    "    #generate symmetric sudokus\n",
    "    sudoku1 = sudoku0[...,::-1,:]\n",
    "    sudoku2 = sudoku0.transpose(0,2,1,3)\n",
    "    sudoku3 = sudoku0[...,::-1,:].transpose(0,2,1,3)\n",
    "    sudoku4 = sudoku0[:,::-1,:,:]\n",
    "    sudoku5 = sudoku0[:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku6 = sudoku0[...,::-1,:][:,::-1,:,:]\n",
    "    sudoku7 = sudoku0[...,::-1,:][:,::-1,:,:].transpose(0,2,1,3)\n",
    "    sudoku = np.concatenate([sudoku0, sudoku1,sudoku2,sudoku3,sudoku4,sudoku5,sudoku6,sudoku7], axis=0)\n",
    "    sudoku = np.repeat(sudoku, repeat, axis=0)\n",
    "    return sudoku\n",
    "\n",
    "query = np.concatenate([np.array(list(harddataset.test[i][0])).astype(np.int64).reshape((1,9,9)) for i in range(len(harddataset.test))])\n",
    "solutions = []\n",
    "ntrys = []\n",
    "\n",
    "for i, q in enumerate(np.array_split(query, query.shape[0]//128)):\n",
    "    puzzle = q\n",
    "    mask = torch.FloatTensor(np.vstack([np.zeros(9)*np.nan,np.eye(9)])[puzzle]).cuda()\n",
    "    solution = np.zeros((puzzle.shape[0], 9, 9))\n",
    "    istrue = np.ones(mask.shape[0])==0\n",
    "    ntry = np.zeros(mask.shape[0])\n",
    "\n",
    "    while True:\n",
    "        batchsize = 512\n",
    "        n_rep = batchsize // np.sum(~istrue)\n",
    "        samples = sampler(score_model,\n",
    "                      (9,9,9),\n",
    "                      mask= torch.FloatTensor(np.repeat(mask.cpu().numpy()[~istrue,:], n_rep, axis=0)).cuda(),\n",
    "                      batch_size=np.sum(~istrue) * n_rep,\n",
    "                      max_time=1,\n",
    "                      min_time=0.01,\n",
    "                      time_dilation=8,\n",
    "                      num_steps=200,\n",
    "                      random_order=False,\n",
    "                      speed_balanced=True,\n",
    "                      device=device)\n",
    "        \n",
    "        acc = np.array(sudoku_acc(samples, return_array=True)).reshape((-1,n_rep))\n",
    "        \n",
    "        istrueinds = np.where(~istrue)[0]\n",
    "        for i in range(acc.shape[0]):\n",
    "            if acc[i,:].any():\n",
    "                ind = i * n_rep + np.where(acc[i,:])[0][0]\n",
    "                solution[np.where(~istrue)[0][i]] = samples[ind].detach().cpu().numpy().argmax(-1) \n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + np.where(acc[i,:])[0] + 1\n",
    "            else:\n",
    "                ntry[istrueinds[i]] = ntry[istrueinds[i]] + acc.shape[1]\n",
    "        istrue[~istrue] =  acc.any(axis=1)\n",
    "\n",
    "        print('correct {} %'.format(100 * np.mean(istrue)))\n",
    "        if np.all(istrue):\n",
    "            print('Bingo!')\n",
    "            break\n",
    "    solutions.append(solution)\n",
    "    ntrys.append(ntry)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((query[:1548,:,:]!=0).sum(axis=-1).sum(axis=-1), np.log10(np.concatenate(ntrys)),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "require(scales)\n",
    "theme_Publication <- function(base_size=14, base_family=\"helvetica\") {\n",
    "      library(grid)\n",
    "      library(ggthemes)\n",
    "      (theme_foundation(base_size=base_size, base_family=base_family)\n",
    "       + theme(plot.title = element_text(face = \"bold\",\n",
    "                                         size = rel(1.2), hjust = 0.5),\n",
    "               text = element_text(),\n",
    "               panel.background = element_rect(colour = NA),\n",
    "               plot.background = element_rect(colour = NA),\n",
    "               panel.border = element_rect(colour = NA),\n",
    "               axis.title = element_text(face = \"bold\",size = rel(1)),\n",
    "               axis.title.y = element_text(angle=90,vjust =2),\n",
    "               axis.title.x = element_text(vjust = -0.2),\n",
    "               axis.text = element_text(), \n",
    "               axis.line = element_line(colour=\"black\"),\n",
    "               axis.ticks = element_line(),\n",
    "               panel.grid.major = element_blank(),\n",
    "               panel.grid.minor = element_blank(),\n",
    "               legend.key = element_rect(colour = NA),\n",
    "               legend.position = \"bottom\",\n",
    "               legend.direction = \"horizontal\",\n",
    "               legend.key.size= unit(1, \"cm\"),\n",
    "               legend.margin = unit(0, \"cm\"),\n",
    "               legend.title = element_text(face=\"italic\"),\n",
    "               plot.margin=unit(c(10,5,5,5),\"mm\"),\n",
    "               strip.background=element_rect(colour=\"#f0f0f0\",fill=\"#f0f0f0\"),\n",
    "               strip.text = element_text(face=\"bold\")\n",
    "          ))\n",
    "      \n",
    "}\n",
    "scale_fill_Publication <- function(...){\n",
    "      discrete_scale(\"fill\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\")), ...)\n",
    "\n",
    "}\n",
    "scale_colour_Publication <- function(...){\n",
    "      discrete_scale(\"colour\",\"Publication\",manual_pal(values = c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\")), ...)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save((solutions, ntrys, ngiven), './hard_sudoku.solutions.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.log10(ntrys[ngiven==24])), np.median(np.log10(ntrys[ngiven==17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i ngiven,ntrys -w 5 -h 3 --unit in --res 300\n",
    "require(ggplot2)\n",
    "ggplot()+geom_boxplot(aes(x=factor(ngiven, levels= seq(34,17,-1)), y=log10(ntrys)), outlier.shape=NA)+\n",
    "    theme_Publication()+xlab('# of clues given')+ylab('# of samples needed to solve \\n (log10)')\n",
    "ggsave('./figures/hard_sudoku_scaling.pdf', device=cairo_pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_ml",
   "language": "python",
   "name": "pytorch_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
